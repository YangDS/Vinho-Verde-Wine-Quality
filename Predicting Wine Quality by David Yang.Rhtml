<!DOCTYPE html>
<html>
<head>
  <title> Analysis Report for Acorns (by David) </title>
</head>

<body>

<p><strong>Predict Wine Quality Using Physicochemical Properties</strong></p>

<p> By:  David Yang (xdyang70@gmail.com)  </p> 

<p> Date:  June 20, 2016 </p>

<p> In this analysis report, I summarize the statistical analyses done on two public data sets (https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/).  The primary goals are to answer three sets of questions.  (1) What measurements are important in determining the quality of a wine? How much can we learn about quality from these measurements? (2) Are there any groups of wines that seem similar in composition and resulting quality?  (3) How can we use this data to predict truly exceptional (or poor) wines? How should we use this information? </p>

<p> Firt, let us do some preparation jobs: set up the working directory, load in necessary libraries, and additional functions that I saved in a different R script file for convinence. You may need to save the file ("Functions Used for Wine Quality Analyses.R") onto your own computer and adjust working directory before running this Rhtml file. </p>

<!--begin.rcode, results = "hide"
  setwd("/Users/davidy/Documents/Personal/Resume/Applications/Acorns/Output")
  suppressMessages(source("Functions Used for Wine Quality Analyses.R"))
  opts_chunk$set(fig.width=8, fig.height=8)
  end.rcode-->

<p> Now, read in the two data sets from their online sources. Check the structure of the data set to ensure they look right. </p> 

<!--begin.rcode
url1 <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'
red_wine_original <- read.csv(url1, header=TRUE, sep=";")
str(red_wine_original)
red_wine = red_wine_original

url2 <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'
white_wine_original <- read.csv(url2, header=TRUE, sep=";")
str(white_wine_original)
white_wine = white_wine_original
  end.rcode-->

<p> As usual, before analyzing the data, I usually conduct data exploration and apply some necessary preprocessings (e.g., transformations to remove skewness and standardization to have mean zero and stdard variance 1). Check to see if the distributions of the variables look acceptable and whether two variablces are perfectly correlated (a collinearity problem). </p>   

<!--begin.rcode, echo=FALSE, message = FALSE, fig.align='center'
#  Explore the pairwise Pearson correlation to see if any two variables are collineared and which variables are correlated to Quality of the Wine 
#  draw_cor_mat(red_wine);    # Red Wine 
#  draw_cor_mat(white_wine);  # White Wine

#  # Using Box plots to explore distributions of the variables in two datasets 
#  draw_boxplots(red_wine, n_row=3, n_col=4, n_tot=12)      # Red Wine
#  draw_boxplots(white_wine, n_row=3, n_col=4, n_tot=12)    # White Wine
end.rcode-->

<!--begin.rcode
  # Apply transformations to make the distributions more symetric and less skewed 
  red_wine[,c(1:2, 4:11)] <- log(red_wine[,c(1:2, 4:11)]); red_wine[,3] <- red_wine[,3]^0.6
  white_wine[, c(1:2, 4:6, 8:11)] <- log(white_wine[, c(1:2, 4:6, 8:11)]);  white_wine[,3] <- white_wine[,3]^0.45 
  
  # Standardize the variables to make them have mean=0 and variance=1 
  red_wine[,1:11] <- as.data.frame( scale( red_wine[,1:11] ))
  white_wine[,1:11] <-as.data.frame( scale( white_wine[,1:11]))
  end.rcode-->

<!--begin.rcode
  # Check for distributions after preprocessings
  draw_boxplots(red_wine, n_row=3, n_col=4, n_tot=12)    # Red Wine
  draw_boxplots(white_wine, n_row=3, n_col=4, n_tot=12)  # White Wine
  end.rcode-->
<!---
Note there is a data point in the White Wine data set, which has <i>density</i> value way above the rest.  It could cause problems in predicting <i>quality</i> when <i>density</i> is included. </p>
 -->

<!--begin.rcode, message = FALSE, fig.align='center'  
  # Show correlation matrix after preprocessings
  draw_cor_mat(red_wine)    # Red Wine
  draw_cor_mat(white_wine)  # White Wine
  end.rcode-->

  
<p><strong>Task 1. Variable Selection & Prediction Power in Predictive Models </strong></p>

<p>Task 1 is primarily a variable selection & prediction power assessment problem within a predictive modeling framework.  There are theoretically many modeling frameworks that I can choose to figure out which subset of the 11 Physicochemical Properties (of the red and white variants of the Portuguese "Vinho Verde" wine) can be selected to predict the wine quality. Here I choose linear regression model mainly because the normality assumption looks acceptable for the distribution of <i>quality</i> (i.e., median of at least 3 evaluations made by wine experts).</p>

<!--begin.rcode,   fig.width=10, fig.height=10
  # Check the normality assumption of Quality for Red Wine  
  par(mfrow=c(2,2))
  # Check the normality assumption of Quality for Red Wine  
  check_normality(red_wine$quality, "Red Wine Quality")   
  check_normality(white_wine$quality, "White Wine Quality")
  end.rcode-->

<p> Let me first answer the first question (What measurements are important in determining the quality of a wine?). Using forward variable selection by comparing AICs, I found seven features that are statistically signifacnt (with p-value < 0.05) in predicting red wine's quality: <i>alcohol, volatile.acidity, sulphates, chlorides, pH, total.sulfur.dioxide</i>, and <i>free.sulfur.dioxide</i>. Thus, I rejected the null hypothesis that these input variables do not make a significantly greater than 0 contribution to the variance of the quality ranking. Adjusted R2 is 0.36, not high; but the p-value of R2 is still smaller than 0.05 and I was at least 95% confident that a linear relationship does exist between some input variables and quality ratings.</p>

<!--begin.rcode
  # Fit a linear regression model with stepwise variable selection for Red Wine
  summary(fit_fwd_red <- fit_lm_step(red_wine)); 
  end.rcode-->

<p> Similarly, I chose the final linear regression model for White Wine and found 10 statistically significant predictors; see the fitting model below. It is bit surprising to me that there are more singificant predictors in predcting white wine quality: <i>density, residual.sugar</i>, and <i>citric.acid </i> are now added to the list. </p>

<!--begin.rcode 
  # Fit a linear regression model with stepwise variable selection for White Wine
  summary(fit_fwd_white <- fit_lm_step(white_wine))
  end.rcode-->

<p>In order to have an idea on comparing the relative predictive power of the selected seven Physicochemical Properties, I resorted to a Bootstap method in assessing the impact of each variable by excluding it from the model and see how much R2 changes. The larger drop in R2 indicates higher importance of the variable in term of its predicting power. There are other metrics used for this assessment and all suggested the consistant rankings. The following plot ranks the relative importance of the chosen physicochemical properties for red and white variants of wine. Now, it looks that <i> alcohol, volatile.acidity, sulphates, chlorides, </i>, and <i> total.sulfur.dioxide </i> are stonger properties than others in predicting red wine quality; while <i> density </i> and <i> free.sulfur.dioxide  </i> are additional important predictors in predicting white wine quality. </p>

<!--begin.rcode
  vi_boot_red <- boot.relimp(fit_fwd_red, b = 500, type = "lmg", rank = TRUE, diff = TRUE, rela = TRUE)
  plot(booteval.relimp(vi_boot_red,sort=TRUE), title="Relative Importance of Predictors for Red Wine")
  end.rcode-->

<!--begin.rcode
  vi_boot_white <- boot.relimp(fit_fwd_white, b = 500, type = "lmg", rank = TRUE, diff = TRUE, rela = TRUE)
  plot(booteval.relimp(vi_boot_white,sort=TRUE), title="Relative Importance of Predictors for White Wine")
  end.rcode-->

<p><strong> The following analyses tries to answer the second one (How much can we learn about quality from these measurements?). </strong></p>

<p> Use k-fold Cross-Validation method, we split the whole data set into k groups, then using each group as testing set to assess the prediction power of the selected model (i.e., the 7-predictor for red wine and the 11-predictor models for white wine) fitted on the rest k-1 data groups. Mean Squared Error (MSE) is a common criteria in comparing level of goodness between models. </p> 
<!--begin.rcode, results = "hide", message=FALSE, fig.width=10, fig.height=4
  par(mfrow=c(1,2))
  suppressWarnings(cv.lm(data = red_wine, fit_fwd_red,  m=5))      # Overall MSE = 0.42 
  suppressWarnings(cv.lm(data = white_wine, fit_fwd_white,  m=5))  # Overall MSE = 0.56
  end.rcode-->

<p>From above cross-validation plots, we can see that the predicted tester ratings are not well aligned with the actual tester ratings, especially for ratings higher than 7 (high quality samples) and those lower than 5 (low quality samples). The MSE of the linear model for red wine is estimated as 0.42, which is fairly accuracy compared to a potential rnage scale from 1-10. The MSE for the white wine model is 0.56, which is little bit higher, but still acceptable. </p>  

<!--begin.rcode
# Prediction Error using Training-Test Split with Bootstrap resampling
  set.seed(123)
  get_accuracy_lm(fit_fwd_red, red_wine)     
  get_accuracy_lm(fit_fwd_white, white_wine)
  end.rcode-->

<p> Many alternative metrics could be conceived to intuitively measure the accuracy in prediction with linear regression model.  Here I introduce one set of them. If a predicted rating is within distance=d from the actual rating, then it is deemed as acceptable. Setting d=0.5 reflect the fact of rounding predicted values to closest integer numbers. Thus it is a good choice for us to see the percentage of cases in the test set whose rating is accuratly preducted using d as cutoff for rounding. When d=0.5, the accuracy is 59.1% for red wine model, and only 52.6% for white wine model.  When d=1.0, then the accuracy becomes 88.8% and 85% repectively.</p>


<p><strong> Task 2: Clustering & Segmentation </strong></p>

<p>In this section, I report the custering analyses done to answer the question: <strong>Are there any groups of wines that seem similar in composition and resulting quality? </strong> If the question were asked as "Are there any groups of wines that seem similar in composition", then I would have chosen any unsupervised clustering methods to do the job using all 11 physicochemical properties. Nonetheless, the question contains "...and resulting quality", which implies that we may not need to bindly put all 11 variables into clustering because not every property is useful in predicting the wine qulity. Thus, in the following, I only show the clustering analyses based on relatively important predictors.<p>

<p> To make my job easier,  I first categorize samples into three groups based on quality ratings: Low (5 or lower), Normal (6), and Top (7 or higher), each is assigned a distinct color for visual inspection. For Red Wine data, I chose the top 3 predictors and for White Wine, top 5. </p>

<!--begin.rcode, results='hide'
 ## Categorizing Quality into 3 Levels: -1 (bad), 0 (normal), +1 (good) and set 3 colors 
 red_wine_sub <- get_subset(red_wine, "Red")$sub
 red_quality_col <- get_subset(red_wine, "Red")$col
 white_wine_sub <- get_subset(white_wine, "White")$sub
 white_quality_col <- get_subset(white_wine, "White")$col
end.rcode-->

<p> When high dimensional data are given, one typical strategy resport to dimensional reduction techniques.  Principal component analysis (PCA) is a popular choice for this. By choosing the top 2 prinicipal components (PC1 and PC2), and show the scatter plot of them with each point colored by one of three options defined for Low, Normal, and Top quality levels. I aimed to see whether the three quality groups can be clearly detected in the 2-dimensional space.    </p> 

<!--begin.rcode, fig.width=8, fig.height=8
  ## PCA (principal Component Analysis) 
  prin_comp_anal(red_wine_sub, red_quality_col, 0.9)        # Red Wine
  prin_comp_anal(white_wine_sub, white_quality_col, 0.8)    # White Wine
  end.rcode-->

<p>Compare the above scatter PCA plots, we can see that the three classes are fairly overlapped, especially for the white wine samples.  This is consistent to the above regression analysis results. But, we do see some good evidence in suggesting calssifying wine samples into similar groups based on the choosen set of relatively important variables. </p>


A limitation of PCA is its less intuitive interpretation becasue all the factors are weightedly summed into subspace.  To observe membership patterns in the original n-dimensional space (n=3 and 5 here), once again, many plotting strategies may exist, athough I only depict two of them below. 

The first option is pairwise scatter plot matrix, which shows how quality groups are distributed in the 2-dim space defined by any pair of features.  By breaking the n-dim space into 2-dim marginal spaces, we lose joint distributionnal patterns. 

<!--begin.rcode, fig.width=8, fig.height=8
  ## Pairwise scatter plot
  pairwise_scatter(red_wine_sub, red_quality_col)
  pairwise_scatter(white_wine_sub, white_quality_col)
  end.rcode-->

To solve the above limitation, I choose parallel coordinates plot to visualize the joint distributions of n features (n=3 for red and 5 for white samples) through the linked lines, each is colored to show categories. From this plot, we can clearly see how difference samples (colored lines) could be clustered based on values of physicochemical traits. For example, Red Wine samples tend to have low quality is they have relatively low level alcohol and sulphates, but high volatile acidity.   

<!--begin.rcode
  ## Parellel Coordinates Plot
  parallel_coordinate_plot(red_wine_sub, 0.5, red_quality_col)
  parallel_coordinate_plot(white_wine_sub, 0.2, white_quality_col)
  end.rcode-->


<p><strong> Task 3: Classification and Prediction  </strong></p>

<p>In this last section, I will answer the last two questions mainly using Random Forest (RF), an ensemble methods for making predictions by employing many small models (i.e., decision trees with small number of nodes). We choose RF because my personal expereince suggests this method has the best classification accuracy. </p>

<p>(A) How can we use this data to predict truly exceptional (or poor) wines?</p>

<p>Again, based on the frequencies of the samples across quality rating levels, we set cutoffs to end up with top (rating>6), normal (rating = 6), and low (rating <6) qualities. Of cause, I can change the cuttoffs to redefine exceptinal good or bad quality wines.  When fit the FR, we would include all 11 predictor variables into the scope of building decisional trees.  This is for two reasons: (1) RF can handle big number of variabls by only choosing randomly a small subset of predictors into building tees; (2) we want to use RF to rank again the importance of physicochemical properties to check if they are consistent to the performance of linear regression. </p>

<!--begin.rcode
  ##  Random Forest for predicting truely exceptional (or poor) wines 
  set.seed(1)
  fit_rf(red_wine, 1000)     # Red Wine
  fit_rf(white_wine, 1000)   # White Wine
  end.rcode-->

<p>From the above fitted RF model with all predictors, we see that the estimated classification accuracy is 75.8% and 71.6%, respectively, for Red and White wines.  This classification rate looks fairly good.  Varible importance is also depicted above. Note that in this secition RF works with categized quality (low, normal, and top), while the original rating scales were direcly applied in Task 1, thus the two models (RF vs Linear Regression) are not absolutely comparble.  In RF we see some evidence that <i>desity</i>  becomes a more predictive of quality level for Red Wine samples. </p>

<p>(B) How should we use this information?</p>

<p>Once we have some idea on which of the 11 physicochemical properties are more strongly correlated with the winw quality ratings, then we can use them to serve us on many directions: e.g., (For example, (1)  we can use the list of strong predictors jointly into a model (e.g., RF, linear regression, or logistic regression models) to predict the quality of a specific variant of red/white wine; (2) one can better control the quality of wines during their whole brewing processes.</p>

</body>
</html>